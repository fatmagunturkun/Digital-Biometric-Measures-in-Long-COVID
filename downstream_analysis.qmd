---
title: 'Modeling Wearables Endpoints'
format: html
embed-resources: true
# code-fold: true
toc: true
#knitr:
#  opts_chunk:
#    dev: "postscript"      
#    fig.ext: "eps"         
#    fig.path: "eps-figs/"
---

## Endpoints for Wearables Analysis

The day- and nighttime endpoints we will consider for the wearables analysis are:

1.  High physical activity
2.  Low physical activity (for day only)
3.  Relative physical activity
4.  Mean peak physical activity
5.  Heart rate (mean, 5th percentile, 95th percentile)

Other endpoints which we will analyze descriptively include step count and oxygen saturation.

<!-- # Setup -->

```{r setup, include = F}
knitr::opts_chunk$set(warning = F, message = F, echo = F) 
knitr::opts_knit$set(root.dir = "~..")
```

```{r, label = 'Load Libraries', message = F}
library(readr)
library(lubridate)
library(dplyr)
library(ggplot2)
library(LCTMtools)
library(lcmm)
library(data.table)
library(splines)
library(tidyr)
library(magrittr)
library(tibble)
library(parallel)
library(kableExtra)
library(mmrm)
library(stringr)
library(reshape2)
library(tableone)
library(gt)
library(gtsummary)
library(grid)
library(gridExtra)
library(ggtext)
```


```{r, label = 'Load Data'}

dat_dt <- fread('data/data_dt.csv')
dat_n <- fread('data/data_n.csv')

clinic_dat <- read_csv('clinical_wearables.csv', show_col_types = F) 
med_dt <- read_csv('full_med_list.csv', col_names = TRUE)
med_dt = med_dt %>% mutate(Adderall = ifelse(grepl(pattern = "adderall", x = tolower(medication)),1,0),
                 propranolol = ifelse(grepl(pattern = "propanolol", x = tolower(medication)),1,propranolol)) %>% 
    select(participant_id, medication, metoprolol, propranolol, amlodipine, Adderall, ends_with("_class")) %>% 
    filter(metoprolol==1 | propranolol==1 |amlodipine==1|Adderall==1) %>%
    filter(medication!="adderall")  %>% 
    mutate(beta_blockers = ifelse(metoprolol==1 | propranolol==1, 1, 
                          ifelse(metoprolol==0 & propranolol==0,0,NA)), 
          calcium_channel_blockers=amlodipine,
          adderall=Adderall) %>% 
  select(participant_id, beta_blockers, calcium_channel_blockers, adderall) 

med_dt=setDT(med_dt)[, lapply(.SD, any), participant_id]
```

```{r, label = 'Read in Symptoms Data', echo = F, warning = F, message = F}
coalesce_across <- function(...){
  coalesce(!!!across(...))
}

# read in data

import_file <- 'DSMB_Report.csv'
prescreen_file <- 'Prescreening.csv'
randomized_file <- 'randomization_list.csv'
treatment_arms_file <- 'treatment_arms_list.csv'
df <- read_csv(import_file, col_types = cols(participant_id = "c", reinf_date = 'D',
                                                           hosp_dx = 'c', withdraw_reason = 'c', ed_dx = 'c',
                                                           comorbid_other = 'c', ps_date = 'D'), show_col_types = F)
prescreen_df <- read_csv(prescreen_file, show_col_types = F) %>%
  select(-mrn)
randomized_list <- read_csv(randomized_file, col_types = cols(participant_id = "c"), show_col_types = F) %>% 
  select(Subject) %>% 
  rename(participant_id = Subject) %>% 
  mutate(Randomization_complete = 1) %>% 
  mutate(participant_id = str_pad(participant_id, 3, pad = '0'))

# treatment arms
treatment_arms <- read_csv(treatment_arms_file, show_col_types = F) %>% 
  mutate(participant_id = ifelse(
    nchar(participant_id) > 3, 
    str_extract(participant_id, '(?<=-)(.*?)(?=-)'),
    participant_id)) %>% 
  mutate(participant_id = str_pad(participant_id, 3, pad = '0')) %>% 
  mutate(participant_id = gsub(' ', '', participant_id)) %>% 
  select(participant_id, rand_assignment) %>% 
  na.omit

randomization_dates <- read_csv('randomization_date.csv', show_col_types = F)

# import date
import_date <- '2023-11-13'
```

```{r, label = 'Clean Data'}
# recode participant ID
randomized_list %<>% mutate(participant_id = ifelse(
  nchar(participant_id) > 3, 
  str_extract(participant_id, '(?<=-)(.*?)(?=-)'),
  participant_id)) %>% 
  mutate(participant_id = str_pad(participant_id, 3, pad = '0')) %>% 
  mutate(participant_id = gsub(' ', '', participant_id))

df %<>% mutate(participant_id = ifelse(
  nchar(participant_id) > 3, 
  str_extract(participant_id, '(?<=-)(.*?)(?=-)'),
  participant_id)) %>% 
  mutate(participant_id = str_pad(participant_id, 3, pad = '0')) %>% 
  mutate(participant_id = gsub(' ', '', participant_id))

df %<>% full_join(randomized_list, by = 'participant_id') %>% 
  mutate(Randomization_complete = ifelse(is.na(Randomization_complete), 0, 1))

# pull out event date from the metadata
df %<>% mutate(event_date = str_extract(redcap_record_metadata, '(?<=eventDate":")(.*?)(?=T)'))

# define columns to keep - select col names matching core symptoms
df_symptoms <- df %>% select(participant_id, redcap_event_name, event_date, Randomization_complete,
                             contains(c('fatigue', 'sob', 'brain', 'bodyache', 'heart', 'stomach'))) %>% 
  select(-contains(c('PROMIS', 'racing')))

# get list of which participants are randomized
randomized_participants <- df_symptoms %>% 
  filter(Randomization_complete == 1 | Randomization_complete == 2) %>%
  pull(participant_id)

# remove rows with all NA
all_na_rows <- rowSums(is.na(df_symptoms)) >= (ncol(df_symptoms) - 4)
df_symptoms <- df_symptoms[!all_na_rows,]

# clean redcap_event_name variable and map to new week variable
df_symptoms %<>% mutate(week = case_when(
  grepl('Visit 1', redcap_event_name) ~ 'Week 0',
  grepl('Day 7', redcap_event_name) ~ 'Week 1',
  grepl('Visit 2', redcap_event_name) ~ 'Week 2',
  grepl('Screening', redcap_event_name) ~ '-1',
  grepl('Week', redcap_event_name) ~ gsub('.*(?=Week)', '', redcap_event_name, perl = T)
)) %>% 
  mutate(week = gsub('Week ', '', week)) %>%
  mutate(week = as.numeric(week)) %>%
  select(participant_id, redcap_event_name, week, event_date, everything()) %>%
  arrange(participant_id, week) %>% # reorder rows
  mutate(week = factor(week)) %>%
  mutate(week = gsub('-1', 'S', week)) %>%
  mutate(participant_id = as.factor(participant_id))

# clean up severity cols
df_symptoms %<>% mutate(fatigue = coalesce_across(contains('fatigue')),
                        sob = coalesce_across(contains('sob')),
                        brainfog = coalesce_across(contains('brainfog')),
                        bodyaches = coalesce_across(contains('bodyache')),
                        heart = coalesce_across(contains('heart')),
                        stomach = coalesce_across(contains('stomach')))

# keep only new cols
df_symptoms %<>% select(participant_id, week, event_date, fatigue, sob, brainfog, bodyaches, heart, stomach)

# remap variables
df_symptoms %<>% mutate(across(c(4:9), ~ case_when(
  . == 0 ~ 'None', 
  . == 1 ~ 'Mild',
  . == 2 ~ 'Moderate',
  . == 3 ~ 'Severe'))) %>%
  mutate(across(c(4:9), ~ factor(., levels = c('None', 'Mild', 'Moderate', 'Severe', 'Missing'))))

# check which participants are not enrolled
unenrolled <- df_symptoms %>% filter(!(participant_id %in% randomized_participants))
df_symptoms %<>% filter(participant_id %in% randomized_participants)

# keep the last row for each participant x week
df_symptoms %<>% group_by(participant_id, week) %>%
  filter(row_number() == n()) %>% ungroup

# calculate difference in dates from initial
df_symptoms %<>% mutate(diff_weeks = difftime(import_date, event_date, units = 'weeks'))

# get dates for participants missing baseline surveys
baseline <- df_symptoms %>% filter(week == '0')
missing_baseline <- df_symptoms %>% filter(!(participant_id %in% baseline$participant_id))
missing_baseline %<>% mutate(diff_weeks = ifelse(week == 'S', diff_weeks, diff_weeks + as.numeric(week)))

df_symptoms_baseline <- df_symptoms %>% 
  filter(week == 'S') %>% 
  mutate(across(fatigue:stomach, ~ ifelse(. %in% c('Moderate', 'Severe'), 1, 0 ))) %>% 
  select(participant_id, fatigue:stomach) %>% 
  mutate(participant_id = as.numeric(as.character(participant_id)))
```

## Temporal patterns of biometrics
The first three days were considered represented a "baseline" or "week 0" for comparison though it should be noted that study drug administration was begun on day 0. Three days was chosen to maximize data from an initial time period while minimizing effects of intervention to mimic as closely as possible to a true pre-drug baseline which was not available for this substudy. Days 4-15 were considered as week 1, encompassing the remainder of the treatment period. After 15 days, we split the follow-up period into 7-day intervals during the follow-up period continuing through week 14.

::: {.panel-tabset}

### Low stringency population (night)

```{r, label = 'Low stringency population (night)'}

dat <- fread('data/data_n.csv')
dat_high <- fread('data/data_n_high_stringency.csv')
dat_dt <- fread('data/data_dt.csv')
dat_dt_high <- fread('data/data_dt_high_stingency.csv')

dat$stepCount_median_n <- dat$stepCount_median_n*60*24
dat_high$stepCount_median_n <- dat_high$stepCount_median_n*60*24
dat_dt$stepCount_median_dt <- dat_dt$stepCount_median_dt*60*24
dat_dt_high$stepCount_median_dt <- dat_dt_high$stepCount_median_dt*60*24

clinic_dat <- read_csv('clinical_wearables_joined.csv', show_col_types = F) 
dat$date <- mdy(dat$date)
dat_high$date <- mdy(dat_high$date)
dat_dt$date <- mdy(dat_dt$date)
dat_dt_high$date <- mdy(dat_dt_high$date)

dat <- dat %>%
  mutate_if(~!is.character(.) & !is.Date(.), as.numeric)
dat_high <- dat_high %>%
  mutate_if(~!is.character(.) & !is.Date(.), as.numeric)
dat_dt <- dat_dt %>%
  mutate_if(~!is.character(.) & !is.Date(.), as.numeric)
dat_dt_high <- dat_dt_high %>%
  mutate_if(~!is.character(.) & !is.Date(.), as.numeric)

df <- dat %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment_y = factor(rand_assignment_y)) %>%
  mutate(across(`0`:`4`, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(outcome = (`4`) / (`1` + `4`) * 100) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(date = parse_date_time(date, orders = c("ymd", "dmy", "mdy", "Ymd", "dmyHM"))) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
df_high <- dat_high %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment_y = factor(rand_assignment_y)) %>% 
  mutate(outcome = (`4`) / (`1` + `4`) * 100) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(date = parse_date_time(date, orders = c("ymd", "dmy", "mdy", "Ymd", "dmyHM"))) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
df_dt <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment_y = factor(rand_assignment_y)) %>% 
  mutate(outcome = (`4`) / (`1`+`2`+`3`+`4`) * 100) %>% 
  mutate(outcome_low = (`1`) / (`1`+`2`+`3`+`4`) * 100) %>% 
  mutate(relative = (outcome-outcome_low) / (outcome+outcome_low) * 100) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(date = parse_date_time(date, orders = c("ymd", "dmy", "mdy", "Ymd", "dmyHM"))) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
df_dt_high <- dat_dt_high %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment_y = factor(rand_assignment_y)) %>% 
  mutate(outcome = (`4`) / (`1`+`2`+`3`+`4`) * 100) %>% 
  mutate(outcome_low = (`1`) / (`1`+`2`+`3`+`4`) * 100) %>% 
  mutate(relative = (outcome-outcome_low) / (outcome+outcome_low) * 100) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(date = parse_date_time(date, orders = c("ymd", "dmy", "mdy", "Ymd", "dmyHM"))) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = TRUE)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup()
df_week_high <- df_high %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = TRUE)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup()
df_week_dt <- df_dt %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = TRUE)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup()
df_week_dt_high <- df_dt_high %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = TRUE)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup()

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome=outcome)
baseline_values_high <- df_week_high %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome=outcome)
baseline_values_dt <- df_week_dt %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome=outcome)
baseline_values_dt_low <- df_week_dt %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome_low=outcome_low)
baseline_values_dt_relative <- df_week_dt %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome_relative=relative)
baseline_values_dt_high <- df_week_dt_high %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome=outcome)
baseline_values_dt_high_low <- df_week_dt_high %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome_low=outcome_low)
baseline_values_dt_high_relative <- df_week_dt %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome_relative=relative)
# Calculate delta scores from the baseline value for each id
df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)
df_week_15_high <- df_week_high %>%
  left_join(baseline_values_high, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)
df_week_15_dt <- df_week_dt %>%
  left_join(baseline_values_dt, by = "app_id") %>%
  left_join(baseline_values_dt_low, by = "app_id") %>%
  left_join(baseline_values_dt_relative, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  mutate(delta_score_low = outcome_low - baseline_outcome_low) %>%
  mutate(delta_score_relative = relative - baseline_outcome_relative)

df_week_15_dt_high <- df_week_dt_high %>%
  left_join(baseline_values_dt_high, by = "app_id") %>%
  left_join(baseline_values_dt_high_low, by = "app_id") %>%
  left_join(baseline_values_dt_high_relative, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  mutate(delta_score_low = outcome_low - baseline_outcome_low) %>%
  mutate(delta_score_relative = relative - baseline_outcome_relative)
#exclude baseline(first row) for each app_id
df_week <- df_week_15 %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 
df_week_high <- df_week_15_high %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 
df_week_dt <- df_week_15_dt %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 
df_week_dt_high <- df_week_15_dt_high %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup()  

# List of outcomes to analyze
outcomes <- c("outcome","heartRate_median_n", "heartRate_std_n", "heartRate_percentile_5_n", "heartRate_percentile_95_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n", "bloodOxygenSaturation_percentile_5_n", "stepCount_median_n", "n_max_sum" )

outcomes_dt <- c("outcome","outcome_low","relative","heartRate_median_dt", "heartRate_std_dt", "heartRate_percentile_5_dt", "heartRate_percentile_95_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt", "bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt", "dt_max_sum" )

# Function to subtract baseline values, excluding week 0 from subtraction
subtract_baseline <- function(df, outcomes) {
  # Filter baseline values and fill missing values with corresponding values from df
  baseline_values <- df %>%
    filter(week_number == 0) %>%
    select(app_id, all_of(outcomes))
  
  for (col in outcomes) {
    if (col != "app_id") {
      baseline_values[[col]] <- ifelse(is.na(baseline_values[[col]]), df[[col]], baseline_values[[col]])
    }
  }
  
  # Left join with baseline values and perform subtraction
  df <- df %>%
    left_join(baseline_values, by = "app_id", suffix = c("", "_baseline")) %>%
    mutate(across(all_of(outcomes), 
                  ~ if_else(week_number == 0, .x, .x - get(paste0(cur_column(), "_baseline"))),
                  .names = "{col}_diff")) %>%
    select(app_id, week_number, period, rand_assignment_y, ends_with("_diff"))
  
  colnames(df) <- gsub("_diff", "", colnames(df))
  return(df)
}

# Function to convert weekly data frame to 5 periods
convert_to_periods <- function(df, outcomes) {
  df$period <- cut(df$week_number,
                   breaks = c(-1, 0, 1, 5, 10, 14),
                   labels = c("Week_0", "Week_1", "Weeks_2_5", "Weeks_6_10", "Weeks_11_14"),
                   right = TRUE)
  df_periods <- df %>%
    group_by(app_id, period, rand_assignment_y) %>%
    summarise(across(all_of(outcomes), ~ mean(.x, na.rm = TRUE))) %>%
    ungroup()
  return(df_periods)
}

# Subtract baseline values, excluding week 0
df_week_15$period <- cut(df_week_15$week_number,
                 breaks = c(-1, 0, 1, 5, 10, 14),
                 labels = c("Week_0", "Week_1", "Weeks_2_5", "Weeks_6_10", "Weeks_11_14"),
                 right = TRUE)
df_week_15_high$period <- cut(df_week_15_high$week_number,
                 breaks = c(-1, 0, 1, 5, 10, 14),
                 labels = c("Week_0", "Week_1", "Weeks_2_5", "Weeks_6_10", "Weeks_11_14"),
                 right = TRUE)
df_week_15_dt$period <- cut(df_week_15_dt$week_number,
                 breaks = c(-1, 0, 1, 5, 10, 14),
                 labels = c("Week_0", "Week_1", "Weeks_2_5", "Weeks_6_10", "Weeks_11_14"),
                 right = TRUE)
df_week_15_dt_high$period <- cut(df_week_15_dt_high$week_number,
                 breaks = c(-1, 0, 1, 5, 10, 14),
                 labels = c("Week_0", "Week_1", "Weeks_2_5", "Weeks_6_10", "Weeks_11_14"),
                 right = TRUE)

df_diff <- subtract_baseline(df_week_15, outcomes)
df_diff_high <- subtract_baseline(df_week_15_high, outcomes)
df_diff_dt <- subtract_baseline(df_week_15_dt, outcomes_dt)
df_diff_dt_high <- subtract_baseline(df_week_15_dt_high, outcomes_dt)

# Convert the data frame to periods
df_periods <- convert_to_periods(df_diff, outcomes)
df_periods_high <- convert_to_periods(df_diff_high, outcomes)
df_periods_dt <- convert_to_periods(df_diff_dt, outcomes_dt)
df_periods_dt_high <- convert_to_periods(df_diff_dt_high, outcomes_dt)

# Define the rename_outcome function
rename_outcome <- function(outcome) {
  name_mapping <- c(
    "outcome" = "% of time in high activity",
    "outcome_low" = "% of time in low activity",
    "relative" = "Relative activity",
    "heartRate_median_n" = "HR median",
    "heartRate_std_n" = "HR SD",
    "heartRate_percentile_5_n" = "HR 5th percentile",
    "heartRate_percentile_95_n" = "HR 95th percentile",
    "heartRateVariability_median_n" = "HRV median",
    "restingHeartRate_median_n" = "RHR median",
    "walkingHeartRateAverage_median_n" = "WHR median",
    "bloodOxygenSaturation_median_n" = "O2 median",
    "bloodOxygenSaturation_percentile_5_n" = "O2 5th percentile",
    "stepCount_median_n" = "SC median",
    "n_max_sum" = "Peak activity"
  )
  return(name_mapping[outcome])
}

# Function to calculate descriptive statistics
calculate_stats <- function(df_periods, outcomes) {
  stats_list <- lapply(outcomes, function(outcome) {
    summary_stats <- df_periods %>%
      group_by(period, rand_assignment_y) %>%
      summarise(
        Median = round(median(.data[[outcome]], na.rm = TRUE), 1),
        IQR = round(IQR(.data[[outcome]], na.rm = TRUE), 1),
        .groups = 'drop'  # Drop the grouping after summarization
      ) %>%
      pivot_wider(
        names_from = rand_assignment_y, 
        values_from = c("Median", "IQR"), 
        names_sep = "_"
      )
    
    # Perform Mann-Whitney U test for each period
    p_values <- df_periods %>%
      group_by(period) %>%
      summarise(
        P_Value = round(wilcox.test(.data[[outcome]] ~ rand_assignment_y, exact = FALSE)$p.value, 2),
        .groups = 'drop'
      )
    
    summary_stats <- summary_stats %>%
      left_join(p_values, by = "period") %>%
      mutate(Outcome = outcome) 
    
    # Format the statistics for the desired output
    formatted_stats <- summary_stats %>%
      unite("Placebo", Median_Placebo, IQR_Placebo, sep = " (") %>%
      mutate(Placebo = paste0(Placebo, ")")) %>%
      unite("Treatment", Median_Treatment, IQR_Treatment, sep = " (") %>%
      mutate(Treatment = paste0(Treatment, ")")) %>%
      pivot_wider(
        names_from = period, 
        values_from = c(Placebo, Treatment, P_Value), 
        names_glue = "{period}_{.value}"
      )
    
    return(formatted_stats)
  })
  
  stats_table <- bind_rows(stats_list)  # Combine all data frames in the list into one

  # Create a sorted list of unique periods
  periods <- unique(df_periods$period)
  periods <- sort(periods)

  # Construct the desired column order
  columns_order <- c("Outcome")
  for (period in periods) {
    columns_order <- c(columns_order, 
                       paste0(period, "_Placebo"), 
                       paste0(period, "_Treatment"), 
                       paste0(period, "_P_Value"))
  }
  
  stats_table <- stats_table %>%
    select(all_of(columns_order))

  return(stats_table)
}

# Calculate descriptive statistics
summary_table <- calculate_stats(df_periods, outcomes)
summary_table$Outcome <- rename_outcome(summary_table$Outcome)

# Create headers for kableExtra
header <- c("Outcome", rep(c("Week 0", "Week 1", "Weeks 2-5", "Weeks 6-10", "Weeks 11-14"), each = 3))
sub_header <- c(" ", rep(c("Placebo", "Treatment", "P"), length(unique(df_periods$period))))

# Format the output using knitr::kable and kableExtra for merged headers
kable(summary_table, row.names = FALSE, col.names = NULL, align = "c") %>%
  kable_styling() %>%
  add_header_above(sub_header, align = "c") %>%
  add_header_above(c(" " = 1, "Week 0" = 3, "Week 1" = 3, "Weeks 2-5" = 3, "Weeks 6-10" = 3, "Weeks 11-14" = 3)) %>%
  row_spec(0, bold = TRUE)

```
### Low stringency population (day)

```{r, label = 'Low stringency population (day) '}

# Calculate descriptive statistics
rename_outcome <- function(outcome) {
  name_mapping <- c(
    "outcome" = "% of time in high activity",
    "outcome_low" = "% of time in low activity",
    "relative" = "Relative activity",
    "heartRate_median_dt" = "HR median",
    "heartRate_std_dt" = "HR SD",
    "heartRate_percentile_5_dt" = "HR 5th percentile",
    "heartRate_percentile_95_dt" = "HR 95th percentile",
    "heartRateVariability_median_dt" = "HRV median",
    "restingHeartRate_median_dt" = "RHR median",
    "walkingHeartRateAverage_median_dt" = "WHR median",
    "bloodOxygenSaturation_median_dt" = "O2 median",
    "bloodOxygenSaturation_percentile_5_dt" = "O2 5th percentile",
    "stepCount_median_dt" = "SC median",
    "dt_max_sum" = "Peak activity"
  )
  return(name_mapping[outcome])
}

summary_table_dt <- calculate_stats(df_periods_dt, outcomes_dt)
summary_table_dt$Outcome <- rename_outcome(summary_table_dt$Outcome)

# Format the output using knitr::kable
kable(summary_table_dt, row.names = FALSE, col.names = NULL, align = "c") %>%
  kable_styling() %>%
  add_header_above(sub_header, align = "c") %>%
  add_header_above(c(" " = 1, "Week 0" = 3, "Week 1" = 3, "Weeks 2-5" = 3, "Weeks 6-10" = 3, "Weeks 11-14" = 3)) %>%
  row_spec(0, bold = TRUE)
```

### High stringency population (night)

```{r, label = 'High stringency population (night) '}
rename_outcome <- function(outcome) {
  name_mapping <- c(
    "outcome" = "% of time in high activity",
    "outcome_low" = "% of time in low activity",
    "relative" = "Relative activity",
    "heartRate_median_n" = "HR median",
    "heartRate_std_n" = "HR SD",
    "heartRate_percentile_5_n" = "HR 5th percentile",
    "heartRate_percentile_95_n" = "HR 95th percentile",
    "heartRateVariability_median_n" = "HRV median",
    "restingHeartRate_median_n" = "RHR median",
    "walkingHeartRateAverage_median_n" = "WHR median",
    "bloodOxygenSaturation_median_n" = "O2 median",
    "bloodOxygenSaturation_percentile_5_n" = "O2 5th percentile",
    "stepCount_median_n" = "SC median",
    "n_max_sum" = "Peak activity"
  )
  return(name_mapping[outcome])
}

# Calculate descriptive statistics
summary_table_high <- calculate_stats(df_periods_high, outcomes)
summary_table_high$Outcome <- rename_outcome(summary_table_high$Outcome)

# Format the output using knitr::kable
kable(summary_table_high, row.names = FALSE, col.names = NULL, align = "c") %>%
  kable_styling() %>%
  add_header_above(sub_header, align = "c") %>%
  add_header_above(c(" " = 1, "Week 0" = 3, "Week 1" = 3, "Weeks 2-5" = 3, "Weeks 6-10" = 3, "Weeks 11-14" = 3)) %>%
  row_spec(0, bold = TRUE)
```

### High stringency population (day)

```{r, label = 'High stringency population (day) '}
rename_outcome <- function(outcome) {
  name_mapping <- c(
    "outcome" = "% of time in high activity",
    "outcome_low" = "% of time in low activity",
    "relative" = "Relative activity",
    "heartRate_median_dt" = "HR median",
    "heartRate_std_dt" = "HR SD",
    "heartRate_percentile_5_dt" = "HR 5th percentile",
    "heartRate_percentile_95_dt" = "HR 95th percentile",
    "heartRateVariability_median_dt" = "HRV median",
    "restingHeartRate_median_dt" = "RHR median",
    "walkingHeartRateAverage_median_dt" = "WHR median",
    "bloodOxygenSaturation_median_dt" = "O2 median",
    "bloodOxygenSaturation_percentile_5_dt" = "O2 5th percentile",
    "stepCount_median_dt" = "SC median",
    "dt_max_sum" = "Peak activity"
  )
  return(name_mapping[outcome])
}
# Calculate descriptive statistics
summary_table_dt_high <- calculate_stats(df_periods_dt_high, outcomes_dt)
summary_table_dt_high$Outcome <- rename_outcome(summary_table_dt_high$Outcome)

# Format the output using knitr::kable
kable(summary_table_dt_high, row.names = FALSE, col.names = NULL, align = "c") %>%
  kable_styling() %>%
  add_header_above(sub_header, align = "c") %>%
  add_header_above(c(" " = 1, "Week 0" = 3, "Week 1" = 3, "Weeks 2-5" = 3, "Weeks 6-10" = 3, "Weeks 11-14" = 3)) %>%
  row_spec(0, bold = TRUE)
```
:::

## Mixed models for repeated measures (MMRM)

::: panel-tabset
### High physical activity (day)

```{r, label = 'Mixed effect repeated models — HPA day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = high_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-30, 30), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-25,xmax=-25,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=25,xmax=25,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment


# Print the plot
print(p)
```

### High physical activity (night)

```{r, label = 'Mixed effect repeated models — HPA night'}
df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = high_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[c(2:15)]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-30, 30), ylim = c(0, 14)) +# Adjust x-axis limits
   annotation_custom(text_left,xmin=-25,xmax=-25,ymin=0.5,ymax=0.5) + 
   annotation_custom(text_right,xmin=25,xmax=25,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Low physical activity (day)

```{r, label = 'Mixed effect repeated models — LPA day'}
df <- dat_dt %>% 
  # filter(app_id %in% ids_keep) %>%
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = low_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)

```

### Relative physical activity (day)

```{r, label = 'Mixed effect repeated models — RPA day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = rel_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-0.5, 0.5), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-0.4,xmax=-0.4,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=0.4,xmax=0.4,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```


### Mean Peak Physical Activity (Day)

```{r, label = 'Mixed effect repeated models — MPPA day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = mean_peak_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-200, 300), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-150,xmax=-150,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=250,xmax=250,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)

```

### Mean Peak Physical Activity (night)

```{r, label = 'Mixed effect repeated models — MPPA night'}
df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = mean_peak_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-400, 800), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-300,xmax=-300,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=650,xmax=650,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Mean heart rate (day)

```{r, label = 'Mixed effect repeated models — MHR day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = mean_heart_rate) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-30, 30), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-25,xmax=-25,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=25,xmax=25,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Mean heart rate (night)

```{r, label = 'Mixed effect repeated models — MHR night'}
df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = mean_heart_rate) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Heart rate — 5th percentile (day)

```{r, label = 'Mixed effect repeated models — HR5 day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = heart_rate_pct5) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Heart rate — 5th percentile (night)

```{r, label = 'Mixed effect repeated models — HR5 night'}
df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = heart_rate_pct5) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Heart rate — 95th percentile (day)

```{r, label = 'Mixed effect repeated models — HR95 day'}
df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = heart_rate_pct95) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

### Heart rate — 95th percentile (night)

```{r, label = 'Mixed effect repeated models — HR95 night'}
df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = heart_rate_pct95) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup

# Group data based on id, week_number, and rand_assignment_x, apply the custom aggregation function
df_week <- df %>%
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

# Get the baseline outcome value for each id (week 0)
baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

# Calculate delta scores from the baseline value for each id
df_week <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome)

df_week <- df_week %>%
  group_by(app_id) %>%
  slice(-1) %>%
  ungroup() 

df_week$participant_sex <- factor(df_week$participant_sex)
df_week$rand_assignment <- factor(df_week$rand_assignment)
df_week$app_id  <- factor(as.integer(factor(df_week$app_id )))
df_week$week_number <- factor(df_week$week_number)
# center age
df_week$age_centered <- df_week$participant_age - mean(df_week$participant_age)

model <- mmrm(
  delta_score ~ rand_assignment + week_number + rand_assignment * week_number + participant_sex + age_centered + baseline_outcome + ar1(week_number|app_id),
  data = df_week,
  control = mmrm_control(method = "Kenward-Roger") #, vcov = "Kenward-Roger-Linear"
)

# Define treatment effects and confidence intervals
treatment_effects <- coef(model)[2:15]
lower_bound <- upper_bound <- numeric(length(treatment_effects))

for (i in 1:length(treatment_effects)) {
  if (i == 1) {
    se <- sqrt(vcov(model)[2, 2])
  } else {
    se <- sqrt(vcov(model)[2, 2] + vcov(model)[i + 1, i + 1] + 2 * vcov(model)[2, i + 1])
  }
  if (i == 1) {
    treatment_effects[i] <- coef(model)[2]
  } else {
    treatment_effects[i] <- coef(model)[2] + coef(model)[i + 1]
  }
  lower_bound[i] <- treatment_effects[i] - 1.96 * se
  upper_bound[i] <- treatment_effects[i] + 1.96 * se
}

# Create a dataframe for treatment effects and confidence intervals
forest_df <- data.frame(
  Week = 2:15,
  Treatment_Effect = treatment_effects,
  Lower_CI = lower_bound,
  Upper_CI = upper_bound
)

# Create labels for treatment effects and confidence intervals
forest_df$Label <- paste(round(forest_df$Treatment_Effect, 1), " (", round(forest_df$Lower_CI, 1), ", ", round(forest_df$Upper_CI, 1), ")", sep = "")

# Reorder the levels of the Week factor
forest_df$Week <- factor(forest_df$Week, levels = 15:2)

options(repr.plot.width = 5, repr.plot.height = 5) 

text_right <- textGrob("Favors NMV/r ->", gp=gpar(fontsize=10))
text_left <- textGrob("<- Favors PBO/r", gp=gpar(fontsize=10))
# Create a forest plot using ggplot2
p <- ggplot(forest_df, aes(y = factor(Week), x = Treatment_Effect, xmin = Lower_CI, xmax = Upper_CI)) +
  geom_point() +
  geom_errorbarh(height = 0.2) +
  labs(y = "", x = "Mean difference between treatment arms") +
  ggtitle("Mean Difference (95% CI)") +  # Add title
  geom_vline(xintercept = 0, linetype = "dashed", color = "black") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  geom_vline(xintercept = forest_df$Treatment_Effect[1], linetype = "dashed", color = "darkred") +
  theme_minimal() +
  scale_y_discrete(labels = function(x) {
    ifelse(as.numeric(x) <= 9, paste("Week ", x, ":  ", forest_df$Label[as.numeric(x)-1], sep = ""), 
           paste("Week ", x, ": ", forest_df$Label[as.numeric(x)-1], sep = ""))
  }) +
  coord_cartesian(xlim = c(-20, 20), ylim = c(0, 14)) +  # Adjust x-axis limits
  annotation_custom(text_left,xmin=-15,xmax=-15,ymin=0.5,ymax=0.5) + 
  annotation_custom(text_right,xmin=15,xmax=15,ymin=0.5,ymax=0.5) +
  theme(axis.title = element_text(color = "black"),
        plot.title.position = "plot",  # Set title position to top
        plot.title = element_text(size = rel(0.85), hjust = 0.03),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(color = "black", hjust = 0))  # Set y-axis label color and alignment

# Print the plot
print(p)
```

:::

```{r, label = 'Read in saved RDS files containing model fits', warning = F, eval = F}
fits_1knot <- read_rds('lcm_1k_fits.rds')
fits_2knot <- read_rds('lcm_2k_fits.rds')
fits_3knot <- read_rds('lcm_3k_fits.rds')
fits_4knot <- read_rds('lcm_4k_fits.rds')
fits_5knot <- read_rds('lcm_5k_fits.rds')
fits_6knot <- read_rds('lcm_6k_fits.rds')
fits_7knot <- read_rds('lcm_7k_fits.rds')
fits_8knot <- read_rds('lcm_8k_fits.rds')
fits_9knot <- read_rds('lcm_9k_fits.rds')
fits_10knot <- read_rds('lcm_10k_fits.rds')
fits_11knot <- read_rds('lcm_11k_fits.rds')
fits_12knot <- read_rds('lcm_12k_fits.rds')

fits_list <- list(fits_1knot, fits_2knot, fits_3knot, fits_4knot, fits_5knot, fits_6knot,
                  fits_7knot, fits_8knot, fits_9knot, fits_10knot, fits_11knot, fits_12knot)
```

```{r, label = 'Read in saved RDS files containing model fits, day/night', warning = F}
rds_files <- list.files("clustering_model_fits", pattern = "\\.rds$", full.names = TRUE)

model_fits_list <- lapply(rds_files, read_rds)
names(model_fits_list) <- rds_files
```

```{r, label = 'Define Helper Functions', message = F}

summarize_fit <- function(fit, i){
  fit_adequacy <- LCTMtoolkit(fit)
  bic <- fit_adequacy$BIC
  entropy <- fit_adequacy$entropy
  rel_entropy <- fit_adequacy$relativeentropy
  
  pp_df <- postprob(fit)[[1]] %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    group_by(class) %>% 
    summarize(N = paste0(first(value), ' (', last(value), '%)')) %>% 
    ungroup %>% 
    pivot_wider(names_from = class, values_from = N)
  
  results_df <- data.frame(`n_knots` = i,
                           `AIC` = aic,
                           `BIC` = bic,
                           `Entropy` = entropy,
                           `Relative_entropy` = rel_entropy) %>% 
    cbind(pp_df)

  return(results_df)
}

n_knots <- c(2, 4, 6, 8)
summarize_fit2 <- function(fit, i){
  k <- n_knots[i]
  fit_adequacy <- LCTMtoolkit(fit)
  aic <- fit_adequacy$AIC
  bic <- fit_adequacy$BIC
  entropy <- fit_adequacy$entropy
  rel_entropy <- fit_adequacy$relativeentropy
  
  pp_df <- postprob(fit)[[1]] %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    group_by(class) %>% 
    summarize(N = paste0(first(value), ' (', last(value), '%)')) %>% 
    ungroup %>% 
    pivot_wider(names_from = class, values_from = N)
  
  results_df <- data.frame(`n_knots` = k,
                           `AIC` = aic,
                           `BIC` = bic,
                           `Entropy` = entropy,
                           `Relative_entropy` = rel_entropy) %>% 
    cbind(pp_df)
  
  return(results_df)
}
```

## Latent Class Trajectory Modeling (LCMM)

In order to perform model selection for each endpoint, we will identify the models with the lowest BIC values and visualize the resulting clusters to assess cluster consistency. The model adequacy metric interpretations as given by the `LCTMtoolkit` package are as follows:

-   Model-specific:
    -   Entropy: close to zero
    -   Relative entropy: close to 1
-   Class-specific:
    -   APPA: greater than 0.7
    -   OCC: greater than 5
    -   Mismatch: close to 0

::: {.panel-tabset}

### High Physical Activity (day)

```{r, label = 'Table for Performance and Classes — High Activity (Day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[17:20]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — High Activity (Day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — High Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — High Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — High Activity (Day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for High Activity (Day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}

plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))

  plot(p, lty = 1, xlab = "Days since Baseline", ylab = '% of time in high activity (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+8, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = .9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = high_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  
  }
)

```
The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap'}

lowest_bic <- low_bic_fits[[3]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = high_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label = paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "High physical activity (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)
```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
   select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))

demo_df <- demo_df %>% filter(!is.na(class))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable

kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for High Activity (Day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### High Physical Activity (night)

```{r, label = 'Table for Performance and Classes — High Activity (Night)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[25:28]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — High Activity (Night)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — High Activity (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — High Activity (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — High Activity (Night)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for High Activity (Night)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}

plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = '% of time in high activity (night)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+16, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_n %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    #mutate(activity2 = `2`) %>% 
    #mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = n_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_n) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
    mutate(outcome = high_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit:  

```{r, label = 'Heatmap for High Activity (Night)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[3]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = high_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "High physical activity (night)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model for High Activity (Night)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_n,heart_rate_pct5,heart_rate_pct95, heartRate_std_n, heartRateVariability_median_n, restingHeartRate_median_n, walkingHeartRateAverage_median_n, bloodOxygenSaturation_median_n, bloodOxygenSaturation_percentile_5_n, stepCount_median_n) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_n","heart_rate_pct5","heart_rate_pct95", "heartRate_std_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n","bloodOxygenSaturation_percentile_5_n", "stepCount_median_n")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for High Activity (Night)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Low Physical Activity (day)

```{r, label = 'Table for Performance and Classes — Low Activity (Day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[29:32]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Low Activity (Day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots', 'AIC','BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Low Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Low Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Low Activity (Day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Low Activity (Day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}

plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = '% of time in low activity (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+11, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = low_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for low pa dt'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[3]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  # filter(app_id %in% ids_keep) %>%
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = low_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Low physical activity (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)
```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model low activity', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
    select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Low Activity (Day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Relative Physical Activity (day)

```{r, label = 'Table for Performance and Classes — relative Activity (Day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[53:56]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — relative Activity (Day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — relative Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — relative Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — relative Activity (Day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for relative Activity (Day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}

plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'relative physical activity (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+0.32, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = rel_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit:  

```{r, label = 'Heatmap for relative pa dt'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[3]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = rel_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Relative physical activity (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model relative activity', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for relative Activity (Day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Mean Peak Physical Activity (Day)

```{r, label = 'Table for Performance and Classes — Mean Peak Activity (Day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[45:48]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Mean Peak Activity (Day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Mean Peak Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Mean Peak Activity (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Mean Peak Activity (Day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Mean Peak Activity (Day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'mean peak physical activity (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+130, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}


plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = mean_peak_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for Mean Peak Activity (Day)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[2]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = mean_peak_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>%
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Mean Peak physical activity (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model Mean Peak Activity (Day)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
   select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Mean Peak Activity (Day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Mean Peak Physical Activity (night)

```{r, label = 'Table for Performance and Classes — Mean Peak Activity (Night)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[49:52]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Mean Peak Activity (Night)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots', 'AIC','BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Mean Peak Activity (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Mean Peak Activity (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Mean Peak Activity (Night)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Mean Peak Activity (Night)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'mean peak physical activity (night)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(85, max(p$pred)+320, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_n %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    #mutate(activity2 = `2`) %>% 
    #mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = n_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_n) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
    mutate(outcome = mean_peak_phys) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for Mean Peak Activity (Night)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[2]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = mean_peak_phys) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Mean Peak physical activity (night)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model for Mean Peak night Activity (Night)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_n,heart_rate_pct5,heart_rate_pct95, heartRate_std_n, heartRateVariability_median_n, restingHeartRate_median_n, walkingHeartRateAverage_median_n, bloodOxygenSaturation_median_n, bloodOxygenSaturation_percentile_5_n, stepCount_median_n) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_n","heart_rate_pct5","heart_rate_pct95", "heartRate_std_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n","bloodOxygenSaturation_percentile_5_n", "stepCount_median_n")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Mean Peak Activity (Night)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Mean heart rate (day)

```{r, label = 'Table for Performance and Classes — Mean heart rate (Day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[37:40]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Mean heart rate (Day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Mean heart rate (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Mean heart rate (Day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Mean heart rate (Day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Mean heart rate (Day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'mean heart rate (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+7, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = mean_heart_rate) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    filter(!is.na(class)) %>%
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit:  

```{r, label = 'Heatmap Mean heart rate day'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[1]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = mean_heart_rate) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>%
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
  p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Mean heart rate (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model Mean heart rate', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
   select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

format_tbl_pct <- function(numer, denom){
  pct <- round(numer/denom, 3) * 100
  return(paste0(numer, ' (', pct, '%)'))
}

```

```{r, label = 'Cluster-heat maps for Mean heart rate (Day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Mean heart rate (night)

```{r, label = 'Table for Performance and Classes — Mean heart rate  (Night)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[39:42]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Mean heart rate (Night)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Mean heart rate (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Mean heart rate (Night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Mean heart rate (Night)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Mean heart rate (Night)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}

plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'mean heart rate (night)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+15, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_n %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    #mutate(activity2 = `2`) %>% 
    #mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = n_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_n) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
    mutate(outcome = mean_heart_rate) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)

```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for Mean heart rate (Night)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[2]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = mean_heart_rate) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Mean heart rate (night)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model for Mean Heart rate (Night)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_n,heart_rate_pct5,heart_rate_pct95, heartRate_std_n, heartRateVariability_median_n, restingHeartRate_median_n, walkingHeartRateAverage_median_n, bloodOxygenSaturation_median_n, bloodOxygenSaturation_percentile_5_n, stepCount_median_n) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_n","heart_rate_pct5","heart_rate_pct95", "heartRate_std_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n","bloodOxygenSaturation_percentile_5_n", "stepCount_median_n", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Mean heart rate (Night)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Heart rate — 5th percentile (day)

```{r, label = 'Table for Performance and Classes — Heart rate — 5th percentile (day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[1:4]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Heart rate — 5th percentile (day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Heart rate — 5th percentile (day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Heart rate — 5th percentile (day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Heart rate — 5th percentile (day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Heart rate — 5th percentile (day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'Heart rate 5th percentile (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+8, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = heart_rate_pct5) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    filter(!is.na(class)) %>%
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)
```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heart rate — 5th percentile (day)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[1]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = heart_rate_pct5) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>%
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Heart rate 5th percentile (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)
```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model Heart rate — 5th percentile (day)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Heart rate — 5th percentile (day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Heart rate — 5th percentile (night)

```{r, label = 'Table for Performance and Classes — Heart rate — 5th percentile (night)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[5:8]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Heart rate — 5th percentile (night)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Heart rate — 5th percentile (night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Heart rate — 5th percentile (night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Heart rate — 5th percentile (night)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Heart rate — 5th percentile (night)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'Heart rate 5th percentile (night)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+6, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_n %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    #mutate(activity2 = `2`) %>% 
    #mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = n_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_n) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
    mutate(outcome = heart_rate_pct5) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  #p <- plot_empirical(low_bic_fits[[i]])
  #print(p)
  }
)
```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for Heart rate — 5th percentile (night)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[1]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_n %>% 
  # filter(app_id %in% ids_keep) %>%
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = heart_rate_pct5) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Heart Rate 5th percentile (night)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model for Heart rate — 5th percentile (night)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
   select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_n,heart_rate_pct5,heart_rate_pct95, heartRate_std_n, heartRateVariability_median_n, restingHeartRate_median_n, walkingHeartRateAverage_median_n, bloodOxygenSaturation_median_n, bloodOxygenSaturation_percentile_5_n, stepCount_median_n) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_n","heart_rate_pct5","heart_rate_pct95", "heartRate_std_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n","bloodOxygenSaturation_percentile_5_n", "stepCount_median_n", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Heart rate — 5th percentile (night)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Heart rate — 95th percentile (day)

```{r, label = 'Table for Performance and Classes — Heart rate — 95th percentile (day)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[9:12]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Heart rate — 95th percentile (day)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Heart rate — 95th percentile (day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Heart rate — 95th percentile (day)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Heart rate — 95th percentile (day)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Heart rate — 95th percentile (day)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'Heart rate 95th percentile (day)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+15, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_dt %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    mutate(activity2 = `2`) %>% 
    mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = dt_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_dt) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
    mutate(outcome = heart_rate_pct95) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    filter(!is.na(class)) %>%
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)
```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heart rate — 95th percentile (day)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[2]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_dt %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity2 = `2`) %>% 
  mutate(activity3 = `3`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity2 + activity3 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = dt_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_dt) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_dt) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_dt) %>% 
  mutate(outcome = heart_rate_pct95) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>%
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Heart rate 95th percentile (day)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model Heart rate — 95th percentile (day)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
   select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_dt,heart_rate_pct5,heart_rate_pct95, heartRate_std_dt, heartRateVariability_median_dt, restingHeartRate_median_dt, walkingHeartRateAverage_median_dt, bloodOxygenSaturation_median_dt, bloodOxygenSaturation_percentile_5_dt, stepCount_median_dt) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))
# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_dt","heart_rate_pct5","heart_rate_pct95", "heartRate_std_dt", "heartRateVariability_median_dt", "restingHeartRate_median_dt", "walkingHeartRateAverage_median_dt", "bloodOxygenSaturation_median_dt","bloodOxygenSaturation_percentile_5_dt", "stepCount_median_dt", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Heart rate — 95th percentile (day)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

### Heart rate — 95th percentile (night)

```{r, label = 'Table for Performance and Classes — Heart rate — 95th percentile (night)', results = 'hide', message = F}
tbl_list <- list()
# change this for different endpoints
fits_list <- model_fits_list[13:16]
tbl_list <- lapply(seq_along(fits_list), function(i){
  temp <- list()
  temp <- lapply(2:5, function(j){
    temp[[j]] <- summarize_fit2(fits_list[[i]][[j]], i)
  })

  tbl_list[[i]] <- temp %<>% bind_rows
})

tbl_df <- tbl_list %<>% 
  bind_rows
```

```{r, label = 'Show Table for Performance — Heart rate — 95th percentile (night)'}
tbl_df %>% 
  kbl(booktabs = T,
      align = 'c',
      col.names = c('Number of knots','AIC', 'BIC', 'Entropy', 'Relative entropy', paste0('Class ', 1:5))) %>% 
  kable_styling(bootstrap_options = c('striped', 'hover'),
                latex_options = c('hold_position'))
```

```{r, label = 'Plot BIC — Heart rate — 95th percentile (night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

bic_p <- ggplot(plot_tbl, aes(x = n_classes, y = BIC, color = knots)) +
  geom_line() +
  labs(title = 'Model BIC by number of classes and knots') +
  theme_bw()

bic_p
```

```{r, label = 'Plot AIC — Heart rate — 95th percentile (night)'}
plot_tbl <- tbl_df %>% 
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  mutate(knots = factor(n_knots))

aic_p <- ggplot(plot_tbl, aes(x = n_classes, y = AIC, color = knots)) +
  geom_line() +
  labs(title = 'Model AIC by number of classes and knots') +
  theme_bw()

aic_p
```

```{r, label = 'Identify subset of best models by BIC — Heart rate — 95th percentile (night)'}
# take the models with the lowest BIC
low_bic <- tbl_df %>%
  mutate(n_classes = rep(2:5, nrow(.) / 4)) %>% 
  arrange(BIC) %>% 
  slice(1:3)

low_bic_knots <- low_bic %>% 
  pull(n_knots)

low_bic_classes <- low_bic %>% 
  pull(n_classes)

low_bic_fits <- list(
  fits_list[[low_bic_knots[1]/2]][[low_bic_classes[1]]], 
  fits_list[[low_bic_knots[2]/2]][[low_bic_classes[2]]],
  fits_list[[low_bic_knots[3]/2]][[low_bic_classes[3]]]
)
```

Mean predicted and empirical trajectories of classes for models with lowest BIC:

```{r, label = 'Plots for Heart rate — 95th percentile (night)', message = F, results = 'hide'}
get_class_pcts <- function(fit){
  pct_vec <- invisible(postprob(fit)[[1]]) %>% 
    as.data.frame %>% 
    rownames_to_column %>% 
    pivot_longer(cols = -rowname, names_to = 'class') %>% 
    filter(rowname == '%') %>% 
    pull(value)
  
  invisible(return(pct_vec))
}


plot_pred <- function(fit, k){
  p <- predictY(fit,
                data.frame(days_since_baseline = seq(0, 120, length = 200)), 
                var.time = 'days_since_baseline', draws = T)
  
  p_pct <- invisible(get_class_pcts(fit))
  
  plot(p, lty = 1, xlab = "Days since Baseline", ylab = 'Heart rate 95th percentile (night)', 
       main = "",
       legend.loc = 'topright', 
       cex = 0.001)
  par(xpd=T)
  legend(80, max(p$pred)+21, legend = paste0('Group ', 1:fit$ng, ' (', p_pct, '%)'),
         col = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise'), lty = 1, cex = 0.9)
  
}

plot_empirical <- function(fit){
  lowest_bic_labels <- fit$pprob
  
  df_empirical <- dat_n %>% 
    # filter(app_id %in% ids_keep) %>%
    left_join(clinic_dat, by = 'app_id') %>% 
    mutate(subject_num = as.numeric(factor(app_id))) %>% 
    mutate(participant_sex = factor(participant_sex)) %>% 
    mutate(rand_assignment = factor(rand_assignment)) %>% 
    mutate(activity0 = `0`) %>% 
    mutate(activity1 = `1`) %>% 
    #mutate(activity2 = `2`) %>% 
    #mutate(activity3 = `3`) %>% 
    mutate(activity4 = `4`) %>% 
    mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
    mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
    mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
    mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
    mutate(mean_peak_phys = n_max_sum) %>% 
    mutate(mean_heart_rate = heartRate_mean_n) %>% 
    mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
    mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
    mutate(outcome = heart_rate_pct95) %>% 
    filter(low_stringency == 1) %>%
    group_by(subject_num) %>% 
    arrange(subject_num, date) %>% 
    mutate(baseline_date = as.Date("2022-01-01")) %>% 
    mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
    ungroup %>% 
    # join the class labels
    left_join(lowest_bic_labels, by = 'subject_num') %>% 
    group_by(class, days_since_baseline) %>% 
    summarize(mean_outcome = mean(outcome), .groups = 'drop') %>% 
    mutate(class = factor(class))
  
  p <- ggplot(df_empirical, aes(x = days_since_baseline, y = mean_outcome, color = class)) +
    geom_line() +
    labs(title = 'Class-specific mean empirical trajectory', y = 'Outcome', x = 'Days since Baseline') +
    scale_color_manual(values = c('black', 'red3', 'palegreen3', 'steelblue', 'turquoise')) +
    theme_bw()
  
  return(p)
}

p_list <- list()
p_list <- lapply(seq_along(low_bic_fits), function(i){
  k <- low_bic_knots[i]
  temp <- plot_pred(low_bic_fits[[i]], k)
  }
)
```

The simplest model (considering the number of classes and knots) was chosen as the final model from the three models with the lowest BIC.

Heatmap of the best model fit: 

```{r, label = 'Heatmap for Heart rate — 95th percentile (night)'}
# replace this later with the selected criterion
lowest_bic <- low_bic_fits[[2]]
lowest_bic_labels <- lowest_bic$pprob

df <- dat_n %>% 
  left_join(clinic_dat, by = 'app_id') %>% 
  mutate(subject_num = as.numeric(factor(app_id))) %>% 
  mutate(participant_sex = factor(participant_sex)) %>% 
  mutate(rand_assignment = factor(rand_assignment)) %>% 
  mutate(activity0 = `0`) %>% 
  mutate(activity1 = `1`) %>% 
  mutate(activity4 = `4`) %>% 
  mutate(across(activity0:activity4, ~ ifelse(. >= 9999, 0, .))) %>% 
  mutate(high_phys = activity4 / (activity1 + activity4) * 100) %>%
  mutate(low_phys = activity1 / (activity1 + activity4) * 100) %>%
  mutate(rel_phys = (high_phys - low_phys) / (high_phys + low_phys)) %>% 
  mutate(mean_peak_phys = n_max_sum) %>% 
  mutate(mean_heart_rate = heartRate_mean_n) %>% 
  mutate(heart_rate_pct5 = heartRate_percentile_5_n) %>% 
  mutate(heart_rate_pct95 = heartRate_percentile_95_n) %>% 
  mutate(outcome = heart_rate_pct95) %>% 
  filter(low_stringency == 1) %>%
  group_by(subject_num) %>% 
  arrange(subject_num, date) %>% 
  mutate(baseline_date = as.Date("2022-01-01")) %>% 
  mutate(days_since_baseline = as.numeric(difftime(date, baseline_date, units = 'days'))) %>% 
  ungroup
  
df_week <- df %>% 
  group_by(app_id, week_number) %>%
  summarise(across(where(is.numeric), ~mean(., na.rm = T)), 
            across(everything(), first), 
            .groups = "drop") %>%
  ungroup

baseline_values <- df_week %>%
  filter(week_number == 0) %>%
  select(app_id, baseline_outcome = outcome)

df_week_15 <- df_week %>%
  left_join(baseline_values, by = "app_id") %>%
  mutate(delta_score = outcome - baseline_outcome) %>%
  group_by(app_id) %>%
  mutate(original_id_order = cur_group_id()) %>% 
  ungroup %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_probability = rowMeans(select(., starts_with('prob')), na.rm = T)) %>% 
  mutate(class_number = class) %>% 
  filter(!is.na(class)) %>%
  arrange(desc(class_number), class_probability)

# Calculate the overall mean and standard deviation of the outcome
population_mean <- mean(df_week_15$outcome, na.rm = TRUE)
population_sd <- sd(df_week_15$outcome, na.rm = TRUE)

# Standardize the outcome using the population mean and standard deviation
df_week_15 <- df_week_15 %>%
  mutate(standardized_outcome = (outcome - population_mean) / population_sd) %>% 
  as.data.frame()

# Pivot the data frame to get the 'week_number' as columns and 'app_id' as rows
heatmap_data <- reshape2::dcast(df_week_15, original_id_order ~ week_number, value.var = "standardized_outcome")

# Convert the data frame to long format for ggplot
heatmap_data_long <- melt(heatmap_data, id.vars = "original_id_order", variable.name = "week_number", 
                          value.name = "standardized_outcome")

# Adjust the week_number to be numeric
heatmap_data_long$week_number <- as.numeric(as.character(heatmap_data_long$week_number))

# Create a custom function to calculate the position of rectangles for each class
calculate_rectangles <- function(df) {
  rectangles <- data.frame()
  for (class in unique(df$class_number)) {
    class_df <- df[df$class_number == class, ]
    min_week <- min(as.numeric(as.character(class_df$week_number))) + 0.5
    max_week <- max(as.numeric(as.character(class_df$week_number))) + 1.5
    min_id <- min(as.numeric(factor(class_df$original_id_order)))
    max_id <- max(as.numeric(factor(class_df$original_id_order)))
    rectangles <- rbind(rectangles, data.frame(class_number = class, min_week = min_week, max_week = max_week, min_id = min_id, max_id = max_id))
  }
  return(rectangles)
}

# Define a custom color palette for classes
class_colors <- rainbow(length(unique(df_week_15$class_number)))

# Plotting the heatmap
p <- ggplot(heatmap_data_long, aes(x = as.factor(week_number), y = factor(original_id_order, levels = unique(df_week_15$original_id_order)), fill = standardized_outcome)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, name = "Standardized Outcome") +
  labs(title = "",
       x = "Weeks",
       y = "") +
  theme_minimal() 

# Calculate rectangles for each class
rectangles_df <- calculate_rectangles(df_week_15)

# Adding rectangles around each class
for (i in 1:nrow(rectangles_df)) {
  # Calculate the height of the rectangle based on the size of the class
  class_size <- rectangles_df$max_id[i] - rectangles_df$min_id[i] + 1
  
  if (i == 1) {
    ymin <- 1
  } else {
    # Calculate the ymin based on the cumulative size of previous classes
    ymin <- sum(rectangles_df$max_id[1:(i - 1)]) + 1
  }
  
  # Adjust the ymax based on the size of the class
  ymax <- ymin + class_size - 1
  
  p <- p + annotate("rect", xmin = rectangles_df$min_week[i], xmax = rectangles_df$max_week[i],
                    ymin = ymin - 0.5, ymax = ymax + 0.5,
                    color = "black", fill = NA, size = 1)
  
  # Add text for class numbers
p <- p + annotate(geom = "richtext", x = mean(c(rectangles_df$min_week[i], rectangles_df$max_week[i])), y = ymax - 1.2,
                    label=paste("<b> Group", rectangles_df$class_number[i],"</b>"), size = 4,fill = NA, label.color = NA, color = "black", hjust = 0.5)
}

# Create a color bar below the plot
p <- p + guides(fill = guide_colorbar(barwidth = 4, barheight = 0.5, title = "Heart rate 95th percentile (night)"),
                position = "bottom") +
     theme(legend.position = "bottom",
           axis.text.y = element_blank()) 
print(p)

```

Baseline characteristics by class of best model fit:

```{r, label = 'Demographic Tables for best-fit model for Heart rate — 95th percentile (night)', echo=FALSE}
ids_link <- clinic_dat %>% 
  distinct(participant_id, app_id)

demo_df <- df %>%
  select(participant_id, subject_num, participant_age, participant_sex, race, ethnic, duration_symptoms_months, bmi, bmi_group,rand_assignment,high_phys,low_phys,rel_phys,mean_peak_phys,heartRate_median_n,heart_rate_pct5,heart_rate_pct95, heartRate_std_n, heartRateVariability_median_n, restingHeartRate_median_n, walkingHeartRateAverage_median_n, bloodOxygenSaturation_median_n, bloodOxygenSaturation_percentile_5_n, stepCount_median_n) %>% 
  group_by(participant_id) %>%
  summarize(across(where(is.numeric), mean, na.rm = TRUE),
            subject_num = first(subject_num),
            participant_age = first(participant_age),
            participant_sex = first(participant_sex),
            race = first(race),
            ethnic = first(ethnic),
            bmi_group = first(bmi_group),
            rand_assignment = first(rand_assignment)) %>% 
  distinct() %>% 
  left_join(lowest_bic_labels, by = 'subject_num') %>% 
  mutate(class_c = paste0('Class ', class)) %>% 
  left_join(ids_link, by = 'participant_id') %>% 
  left_join(df_symptoms_baseline, by = 'participant_id') %>% 
  mutate(race = case_when(
    race == 2 ~ 'Asian',
    race == 4 ~ 'Black or African American',
    race == 5 ~ 'White',
    race == 6 ~ 'More than one race',
    TRUE ~ 'Other'
  )) %>% 
  mutate(race = factor(race, levels = c('Asian','Black or African American','White','More than one race','Other'))) %>% 
  mutate(participant_sex = ifelse(participant_sex == 1, 'Male', 'Female')) %>% 
  mutate(bmi_group = paste0(toupper(substr(bmi_group, 1, 1)), substr(bmi_group, 2, nchar(bmi_group)))) %>% 
  mutate(bmi_group = factor(bmi_group, levels = c('Underweight', 'Normal', 'Overweight', 'Obese')))
demo_df <- demo_df %>% filter(!is.na(class)) %>%
  merge(., med_dt %>% select(participant_id, beta_blockers, calcium_channel_blockers, adderall), by="participant_id",all.x=TRUE) %>%
  mutate(beta_blockers=replace_na(beta_blockers, 0),
         calcium_channel_blockers=replace_na(calcium_channel_blockers, 0),
         adderall=replace_na(adderall, 0)) %>%
  mutate(beta_blockers=ifelse(beta_blockers==1, "Yes", "No"),
         calcium_channel_blockers=ifelse(calcium_channel_blockers==1, "Yes", "No"), 
         adderall=ifelse(adderall==1, "Yes", "No"))

# Define the continuous and categorical variables
vars <- c("participant_age", "duration_symptoms_months", "bmi","participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment","high_phys","low_phys","rel_phys","mean_peak_phys","heartRate_median_n","heart_rate_pct5","heart_rate_pct95", "heartRate_std_n", "heartRateVariability_median_n", "restingHeartRate_median_n", "walkingHeartRateAverage_median_n", "bloodOxygenSaturation_median_n","bloodOxygenSaturation_percentile_5_n", "stepCount_median_n", "beta_blockers", "calcium_channel_blockers", "adderall")
categorical_vars <- c("participant_sex", "race", "ethnic", "bmi_group", "fatigue", "sob", "brainfog", "bodyaches", "heart", "stomach","rand_assignment")

# Calculate SMDs using the tableone package
table1 <- CreateTableOne(
  vars = vars, 
  data = demo_df, 
  strata = "class_c", 
  test = FALSE,
  factorVars = categorical_vars
)

# Print table1 with standardized mean differences (SMD)
table1_output <- print(table1, smd = TRUE, printToggle = FALSE)

# Convert to data frame if it's not already
table1_output <- as.data.frame(table1_output, stringsAsFactors = FALSE)

# Function to round numeric columns appropriately
round_columns <- function(df) {
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    
    if (col_name == "SMD") {
      # Handle SMD column specifically
      df[[col_name]] <- as.character(round(as.numeric(col_data), 2))
      # Replace NA values in SMD column with an empty string
      df[[col_name]][is.na(df[[col_name]])] <- ""
    } else {
      # Check if the column contains mean (SD) format
      if (any(grepl("\\(", col_data))) {
        # Process mean (SD) columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("\\(", x)) {
            mean_val <- as.numeric(sub(" \\(.*", "", x))
            sd_val <- as.numeric(sub(".*\\((.*)\\).*", "\\1", x))
            return(paste0(round(mean_val, 1), " (", round(sd_val, 1), ")"))
          } else {
            return(x)
          }
        })
      } else if (any(grepl("%", col_data))) {
        # Process percentage columns
        df[[col_name]] <- sapply(col_data, function(x) {
          if (grepl("%", x)) {
            num_val <- as.numeric(sub(" .*", "", x))
            return(paste0(round(num_val, 1), " ", sub("^[0-9.]+", "", x)))
          } else {
            return(x)
          }
        })
      } else {
        # Process other numeric columns
        num_data <- suppressWarnings(as.numeric(col_data))
        if (all(!is.na(num_data))) {
          df[[col_name]] <- as.character(round(num_data, 1))
        } else {
          df[[col_name]] <- col_data
        }
      }
    }
  }
  return(df)
}

# Apply the rounding function
table1_output_rounded <- round_columns(table1_output)

# Assign column names back to the data frame
names(table1_output_rounded) <- colnames(table1_output)

# Format the output using knitr::kable
knitr::kable(table1_output_rounded)

```

```{r, label = 'Cluster-heat maps for Heart rate — 95th percentile (night)', eval = F}

consenus_matrices = lapply(names(boot_class_dfs), function(outcome) {
  c_mat = consensus_matrix(boot_class_dfs[[outcome]])
  rownames(c_mat) = colnames(c_mat) = rownames(boot_class_dfs[[outcome]])
  return(c_mat)
})
names(consenus_matrices) = names(boot_class_dfs)

p1 = reshape2::melt(consenus_matrices[[outcome]][id_order, id_order]) %>% 
  mutate(Var1 = factor(Var1, levels = id_order), 
         Var2 = factor(Var2, levels = id_order)) %>% 
  ggplot(aes(x = Var1, y = Var2, fill = value)) + 
  geom_tile() + 
  scale_fill_gradient2("Consensus index", low = 0, high = "firebrick3") + 
  xlab(NULL) + ylab(NULL) +
  theme(axis.text.x=element_blank(), 
        axis.ticks.x=element_blank(), 
        axis.text.y=element_blank(), 
        axis.ticks.y=element_blank()) 
print(p1)

```

:::
